{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plagiarism Detection, Feature Engineering\n",
    "\n",
    "For this project I am  building a plagiarism detector that examines an answer text file and performs binary classification; predicting either plagiarized or not, depending on how similar that text file is to the source file.\n",
    "\n",
    "We will cover the cleaning, processing, and feature engineering of the data in this notebook. We will also select down a few features for modeling at the very end of this notebook. We will break this notebook down into several general steps outlined below:\n",
    "\n",
    "* Clean and pre-process the data.\n",
    "* Define features for similarity between an input answer text and a source text.\n",
    "* Select \"good\" features, by analyzing the correlations between different features.\n",
    "* Create train/test `.csv` files that hold the relevant features and class labels for train/test data points.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plagiarism dataset is made of multiple text files; each of these files has characteristics that are is summarized in a `.csv` file named `file_information.csv`, which we can read in using `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Task</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g0pA_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g0pA_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>cut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g0pA_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g0pA_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>heavy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g0pA_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>g0pB_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>g0pB_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>g0pB_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>cut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>g0pB_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>g0pB_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>heavy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             File Task Category\n",
       "0  g0pA_taska.txt    a      non\n",
       "1  g0pA_taskb.txt    b      cut\n",
       "2  g0pA_taskc.txt    c    light\n",
       "3  g0pA_taskd.txt    d    heavy\n",
       "4  g0pA_taske.txt    e      non\n",
       "5  g0pB_taska.txt    a      non\n",
       "6  g0pB_taskb.txt    b      non\n",
       "7  g0pB_taskc.txt    c      cut\n",
       "8  g0pB_taskd.txt    d    light\n",
       "9  g0pB_taske.txt    e    heavy"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = 'data/file_information.csv'\n",
    "plagiarism_df = pd.read_csv(csv_file)\n",
    "\n",
    "plagiarism_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Pre-Process the Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we are going to encode the tasks, categories, and classes for each observation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_encoder(row, col_flag):\n",
    "    '''\n",
    "        Conditional network to encode classes, tasks, categories\n",
    "        \n",
    "        Returns: label of the class and category\n",
    "    '''\n",
    "    if col_flag == 'class':\n",
    "        if row == 'non':\n",
    "            label = 0\n",
    "        if row == 'orig':\n",
    "            label = -1\n",
    "        if row in ['heavy','light','cut']:\n",
    "            label = 1\n",
    "        return label\n",
    "    if col_flag == 'category':\n",
    "        if row == 'non':\n",
    "            label = 0 \n",
    "        if row == 'heavy':\n",
    "            label = 1\n",
    "        if row == 'light':\n",
    "            label = 2\n",
    "        if row == 'cut':\n",
    "            label = 3\n",
    "        if row == 'orig':\n",
    "            label = -1\n",
    "        return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in a csv file and return a transformed dataframe\n",
    "def numerical_dataframe(csv_file='data/file_information.csv'):\n",
    "    '''\n",
    "    Reads a csv file that has `File`, `Category` and `Task` columns.\n",
    "    Applies the col_encoder function to the dataframe produced from csv file\n",
    "       param csv_file: The directory for the file_information.csv file\n",
    "       return: A dataframe with numerical categories and a new `Class` label column\n",
    "    '''\n",
    "    \n",
    "    df = pd.read_csv(csv_file)\n",
    "    df['Class'] = df.Category.apply(lambda r: col_encoder(r, 'class'))\n",
    "    df['Category'] = df.Category.apply(lambda r: col_encoder(r, 'category'))\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Task</th>\n",
       "      <th>Category</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g0pA_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g0pA_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g0pA_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g0pA_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g0pA_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>g0pB_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>g0pB_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>g0pB_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>g0pB_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>g0pB_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             File Task  Category  Class\n",
       "0  g0pA_taska.txt    a         0      0\n",
       "1  g0pA_taskb.txt    b         3      1\n",
       "2  g0pA_taskc.txt    c         2      1\n",
       "3  g0pA_taskd.txt    d         1      1\n",
       "4  g0pA_taske.txt    e         0      0\n",
       "5  g0pB_taska.txt    a         0      0\n",
       "6  g0pB_taskb.txt    b         0      0\n",
       "7  g0pB_taskc.txt    c         3      1\n",
       "8  g0pB_taskd.txt    d         2      1\n",
       "9  g0pB_taske.txt    e         1      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# informal testing, print out the results of a called function\n",
    "transformed_df = numerical_dataframe(csv_file ='data/file_information.csv')\n",
    "\n",
    "transformed_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Processing & Splitting Data\n",
    "\n",
    "We will use two similarity metrics for this project, and to create those metrics we need the text. We have built out some text preprocessing functions to clean up the data for this notebook. See the file `helpers.py` for code and documentation for text preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Task</th>\n",
       "      <th>Category</th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g0pA_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inheritance is a basic concept of object orien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g0pA_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>pagerank is a link analysis algorithm used by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g0pA_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>the vector space model also called term vector...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g0pA_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>bayes theorem was names after rev thomas bayes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g0pA_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dynamic programming is an algorithm design tec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             File Task  Category  Class  \\\n",
       "0  g0pA_taska.txt    a         0      0   \n",
       "1  g0pA_taskb.txt    b         3      1   \n",
       "2  g0pA_taskc.txt    c         2      1   \n",
       "3  g0pA_taskd.txt    d         1      1   \n",
       "4  g0pA_taske.txt    e         0      0   \n",
       "\n",
       "                                                Text  \n",
       "0  inheritance is a basic concept of object orien...  \n",
       "1  pagerank is a link analysis algorithm used by ...  \n",
       "2  the vector space model also called term vector...  \n",
       "3  bayes theorem was names after rev thomas bayes...  \n",
       "4  dynamic programming is an algorithm design tec...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "# create a text column \n",
    "text_df = utils.create_text_column(transformed_df)\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample processed text:\n",
      "\n",
      " inheritance is a basic concept of object oriented programming where the basic idea is to create new classes that add extra detail to existing classes this is done by allowing the new classes to reuse the methods and variables of the existing classes and new methods and classes are added to specialise the new class inheritance models the is kind of relationship between entities or objects  for example postgraduates and undergraduates are both kinds of student this kind of relationship can be visualised as a tree structure where student would be the more general root node and both postgraduate and undergraduate would be more specialised extensions of the student node or the child nodes  in this relationship student would be known as the superclass or parent class whereas  postgraduate would be known as the subclass or child class because the postgraduate class extends the student class  inheritance can occur on several layers where if visualised would display a larger tree structure for example we could further extend the postgraduate node by adding two extra extended classes to it called  msc student and phd student as both these types of student are kinds of postgraduate student this would mean that both the msc student and phd student classes would inherit methods and variables from both the postgraduate and student classes  \n"
     ]
    }
   ],
   "source": [
    "# print out a sample text\n",
    "row_idx = 0 \n",
    "\n",
    "sample_text = text_df.iloc[0]['Text']\n",
    "\n",
    "print('Sample processed text:\\n\\n', sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and test sets\n",
    "\n",
    "The next cell will add a `Datatype` column to a given DataFrame to indicate if the record is: \n",
    "* `train` - Training data, for model training.\n",
    "* `test` - Testing data, for model evaluation.\n",
    "* `orig` - The task's original answer from wikipedia.\n",
    "\n",
    "### Stratified sampling\n",
    "\n",
    "Again, we are using some helper functions from `helpers.py`. This implements [stratified random sampling](https://en.wikipedia.org/wiki/Stratified_sampling) to randomly split data by task & plagiarism amount. Stratified sampling ensures that we get well balanced training and test data. Approximately 25% of the data is held out for testing and 75% for training.\n",
    "\n",
    "The function **train_test_dataframe** takes in a DataFrame that it assumes has `Task` and `Category` columns, and, returns a modified dataframe that indicates which `Datatype` (train, test, or orig). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Task</th>\n",
       "      <th>Category</th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "      <th>Datatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g0pA_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inheritance is a basic concept of object orien...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g0pA_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>pagerank is a link analysis algorithm used by ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g0pA_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>the vector space model also called term vector...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g0pA_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>bayes theorem was names after rev thomas bayes...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g0pA_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dynamic programming is an algorithm design tec...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>g0pB_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inheritance is a basic concept in object orien...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>g0pB_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pagerank pr refers to both the concept and the...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>g0pB_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>vector space model is an algebraic model for r...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>g0pB_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>bayes theorem relates the conditional and marg...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>g0pB_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>dynamic programming is a method for solving ma...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             File Task  Category  Class  \\\n",
       "0  g0pA_taska.txt    a         0      0   \n",
       "1  g0pA_taskb.txt    b         3      1   \n",
       "2  g0pA_taskc.txt    c         2      1   \n",
       "3  g0pA_taskd.txt    d         1      1   \n",
       "4  g0pA_taske.txt    e         0      0   \n",
       "5  g0pB_taska.txt    a         0      0   \n",
       "6  g0pB_taskb.txt    b         0      0   \n",
       "7  g0pB_taskc.txt    c         3      1   \n",
       "8  g0pB_taskd.txt    d         2      1   \n",
       "9  g0pB_taske.txt    e         1      1   \n",
       "\n",
       "                                                Text Datatype  \n",
       "0  inheritance is a basic concept of object orien...    train  \n",
       "1  pagerank is a link analysis algorithm used by ...    train  \n",
       "2  the vector space model also called term vector...    train  \n",
       "3  bayes theorem was names after rev thomas bayes...    train  \n",
       "4  dynamic programming is an algorithm design tec...    train  \n",
       "5  inheritance is a basic concept in object orien...    train  \n",
       "6  pagerank pr refers to both the concept and the...    train  \n",
       "7  vector space model is an algebraic model for r...    train  \n",
       "8  bayes theorem relates the conditional and marg...    train  \n",
       "9  dynamic programming is a method for solving ma...    train  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = 945\n",
    "\n",
    "# create new df with Datatype (train, test, orig) column\n",
    "complete_df = utils.train_test_dataframe(text_df, random_seed=random_seed)\n",
    "\n",
    "complete_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Similarity Features \n",
    "\n",
    "We will use [this paper on plagiarism detection](https://s3.amazonaws.com/video.udacity-data.com/topher/2019/January/5c412841_developing-a-corpus-of-plagiarised-short-answers/developing-a-corpus-of-plagiarised-short-answers.pdf) to calculate some similarity features for this data. \n",
    "\n",
    "> Features like **containment** and **longest common subsequence**. \n",
    "\n",
    "\n",
    "## Feature Engineering\n",
    "\n",
    "### Containment\n",
    "\n",
    "First we will create **containment features**. Containment works on [n-grams](https://en.wikipedia.org/wiki/N-gram). \n",
    "\n",
    "> Containment is the mathematical intersection of the n-gram word count of the Wikipedia Source Text (S) with the n-gram word count of the input Answer Text (A) *divided* by the n-gram word count of the Input Answer Text.\n",
    "\n",
    "$$ \\frac{\\sum{count(\\text{ngram}_{A}) \\cap count(\\text{ngram}_{S})}}{\\sum{count(\\text{ngram}_{A})}} $$\n",
    "\n",
    "If the two texts have no n-grams in common, the containment will be 0, but if _all_ their n-grams intersect then the containment will be 1.\n",
    "\n",
    "\n",
    "### Containment calculation\n",
    "\n",
    "We will use a [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) to produce the n-grams.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_count_vector(corpus, ngrams):\n",
    "    '''\n",
    "    Makes a count vectorizer matrix based on the number of ngrams. \n",
    "    \n",
    "    param corpus: an array of strings that are input text to CountVectorized.\n",
    "    param ngrams: the max number of ngrams to be calculated. \n",
    "    \n",
    "    return: CountVectorizer object\n",
    "    '''\n",
    "    try: \n",
    "        CountVectorizer()\n",
    "    except IOError:\n",
    "        print('Import CountVectorizer from sklean.feature_extraction.text')\n",
    "    count_vec = CountVectorizer(analyzer='word', ngram_range=(ngrams,ngrams))\n",
    "    return count_vec.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_containment(df, n, answer_filename):\n",
    "    '''\n",
    "    Calculates the containment between an input text and its associated source text.\n",
    "    This function creates a count of ngrams (of a size, n) for each text file.\n",
    "    Then calculates the containment.\n",
    "       param df: A dataframe \n",
    "       param n: An integer that defines the ngram size\n",
    "       param answer_filename: A filename for am input answer text\n",
    "       \n",
    "       return: A single containment value that represents the similarity\n",
    "           between an input text and its source text.\n",
    "    '''\n",
    "    task_letter_idx = -5\n",
    "    task = answer_filename[task_letter_idx]\n",
    "\n",
    "    source = df[(df['Task'] == task) & (df['Datatype']=='orig')]['Text']\n",
    "    source_idx = source.index[0]\n",
    "    \n",
    "    answer = df[df['File'] == answer_filename]['Text']\n",
    "    answer_idx = answer.index[0]\n",
    "    \n",
    "    count_vec = make_count_vector([answer[answer_idx], source[source_idx]], n)\n",
    "    # intersection can be thought of as the minimum between the source and answer array\n",
    "    intersect_sum = np.minimum(count_vec[0].toarray(), count_vec[1].toarray()).sum()\n",
    "      \n",
    "    answer_sum = count_vec[0].toarray().sum()\n",
    "    containment = intersect_sum/answer_sum\n",
    "    \n",
    "    return containment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original category values: \n",
      " [0, 3, 2, 1, 0] /n\n",
      "3-gram containment values: \n",
      " [0.009345794392523364, 0.9641025641025641, 0.6136363636363636, 0.15675675675675677, 0.031746031746031744]\n"
     ]
    }
   ],
   "source": [
    "# Let's make sure this works like we want\n",
    "n = 3\n",
    "\n",
    "# The first few files\n",
    "test_indices = range(5)\n",
    "\n",
    "# Calculate containment\n",
    "category_vals = []\n",
    "containment_vals = []\n",
    "for i in test_indices:\n",
    "    category_vals.append(complete_df.loc[i, 'Category'])\n",
    "    filename = complete_df.loc[i, 'File']\n",
    "    # Run containment calculation\n",
    "    c = calculate_containment(complete_df, n, filename)\n",
    "    containment_vals.append(c)\n",
    "\n",
    "print('Original category values: \\n', category_vals, '/n')\n",
    "print(str(n)+'-gram containment values: \\n', containment_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Longest Common Subsequence\n",
    "\n",
    "Containment a good way to find overlap in word usage between two documents; it may help identify cases of cut-and-paste as well as paraphrased levels of plagiarism. Since plagiarism is a fairly complex task with varying levels, it's often useful to include other measures of similarity. The paper also discusses a feature called **longest common subsequence**.\n",
    "\n",
    "> The longest common subsequence is the longest string of words (or letters) that are *the same* between the Wikipedia Source Text (S) and the Student Answer Text (A). This value is also normalized by dividing by the total number of words (or letters) in the  Student Answer Text. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LCS Calculation\n",
    "\n",
    "I found this video helpful in determining how to calculate LCS \n",
    "\n",
    "[LCS video](https://www.youtube.com/watch?v=NnD96abizww)\n",
    "\n",
    "As an example of how to calculate the LCS consider the following simple example:\n",
    "\n",
    "* A = \"ABCD\"\n",
    "* S = \"BD\"\n",
    "\n",
    "Here the longest subsequence of _letters_ here is 2 (B and D are in sequence in both strings). And we can calculate LCS by looking at relationships between each letter in the two strings, A and S.\n",
    "\n",
    "As a matrix this looks like the following:\n",
    "\n",
    "<img src='img/matrix_1.png' width=40% />\n",
    "\n",
    "This starts out as a matrix that has as many columns and rows as letters in the strings S and O **+1** additional row and column, filled with zeros on the top and left sides. Such that, instead of a 2x4 matrix it is a 3x5.\n",
    "\n",
    "Now, we can fill this matrix up by breaking it into smaller LCS problems. For example, let's first look at the shortest substrings: the starting letter of A and S. We'll first ask, what is the Longest Common Subsequence between these two letters \"A\" and \"B\"? \n",
    "\n",
    "**Here, the answer is zero.**\n",
    "\n",
    "<img src='img/matrix_2.png' width=30% />\n",
    "\n",
    "Then, what is the LCS between \"AB\" and \"B\"?\n",
    "\n",
    "**We have a match, and can assign it a value of 1**.\n",
    "\n",
    "<img src='img/matrix_3_match.png' width=25% />\n",
    "\n",
    "If we continue, we get to a final matrix that looks as follows, with a **2** in the bottom right corner.\n",
    "\n",
    "<img src='img/matrix_6_complete.png' width=25% />\n",
    "\n",
    "The final LCS will be that value **2** *normalized* by the number of n-grams in A. So, our normalized value is **0.5**.\n",
    "\n",
    "### The matrix rules\n",
    "\n",
    "One thing to notice here is that, you can efficiently fill up this matrix one cell at a time. Each grid cell only depends on the values in the grid cells that are directly on top and to the left of it, or on the diagonal/top-left. The rules are as follows:\n",
    "\n",
    "* Start with a matrix that has one extra row and column of zeros.\n",
    "* As you traverse your string:\n",
    "    * If there is a match, fill that grid cell with the value to the top-left of that cell *plus* one. So, in our case, when we found a matching B-B, we added +1 to the value in the top-left of the matching cell, 0.\n",
    "    * If there is not a match, take the *maximum* value from either directly to the left or the top cell, and carry that value over to the non-match cell.\n",
    "\n",
    "<img src='img/matrix_rules.png' width=50% />\n",
    "\n",
    "After completely filling the matrix, **the bottom-right cell will hold the non-normalized LCS value**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = \"i think pagerank is a link analysis algorithm used by google that uses a system of weights attached to each element of a hyperlinked set of documents\"\n",
    "S = \"pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the normalized LCS given an answer text and a source text\n",
    "def lcs_norm_word(answer_text, source_text):\n",
    "    '''\n",
    "    Computes the longest common subsequence of words in two texts; returns a normalized value.\n",
    "       param answer_text: The pre-processed text for an answer text\n",
    "       param source_text: The pre-processed text for an answer's associated source text\n",
    "       return: A normalized LCS value'''\n",
    "    \n",
    "    ans = answer_text.split()\n",
    "    src = source_text.split()\n",
    "    mat = np.zeros((len(ans)+1, len(src)+1))\n",
    "    \n",
    "    for i in range(len(ans)):\n",
    "        for j in range(len(src)):\n",
    "            if ans[i] == src[j]:\n",
    "                mat[i+1,j+1] = mat[i,j]+1\n",
    "            else: \n",
    "                mat[i+1,j+1] = max(mat[i,j+1], mat[i+1,j])\n",
    "                \n",
    "    lcs_score = mat[-1,-1] / len(ans)\n",
    "    return lcs_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, take a look at a few resultant values for `lcs_norm_word`. Just like before, you should see that higher values correspond to higher levels of plagiarism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original category values: \n",
      " [0, 3, 2, 1, 0]\n",
      "\n",
      "Normalized LCS values: \n",
      " [0.1917808219178082, 0.8207547169811321, 0.8464912280701754, 0.3160621761658031, 0.24257425742574257]\n"
     ]
    }
   ],
   "source": [
    "test_indices = range(5) # look at first few files\n",
    "\n",
    "category_vals = []\n",
    "lcs_norm_vals = []\n",
    "# iterate through first few docs and calculate LCS\n",
    "for i in test_indices:\n",
    "    category_vals.append(complete_df.loc[i, 'Category'])\n",
    "    # get texts to compare\n",
    "    answer_text = complete_df.loc[i, 'Text'] \n",
    "    task = complete_df.loc[i, 'Task']\n",
    "    # we know that source texts have Class = -1\n",
    "    orig_rows = complete_df[(complete_df['Class'] == -1)]\n",
    "    orig_row = orig_rows[(orig_rows['Task'] == task)]\n",
    "    source_text = orig_row['Text'].values[0]\n",
    "    \n",
    "    # calculate lcs\n",
    "    lcs_val = lcs_norm_word(answer_text, source_text)\n",
    "    lcs_norm_vals.append(lcs_val)\n",
    "\n",
    "# print out result, does it make sense?\n",
    "print('Original category values: \\n', category_vals)\n",
    "print()\n",
    "print('Normalized LCS values: \\n', lcs_norm_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Create All Features\n",
    "\n",
    "Let's bring all this together to finalize our feature engineered dataset. \n",
    "\n",
    "### Creating Multiple Containment Features\n",
    "\n",
    "> This function returns a list of containment features, calculated for a given `n` and for *all* files in a df (assumed to the the `complete_df`).\n",
    "\n",
    "For our original files, the containment value is set to a special value, -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function returns a list of containment features, calculated for a given n \n",
    "def create_containment_features(df, n, column_name=None):\n",
    "    \n",
    "    containment_values = []\n",
    "    \n",
    "    if(column_name==None):\n",
    "        column_name = 'c_'+str(n) # c_1, c_2, .. c_n\n",
    "    \n",
    "    for i in df.index:\n",
    "        file = df.loc[i, 'File']\n",
    "        # Computes features using calculate_containment function\n",
    "        if df.loc[i,'Category'] > -1:\n",
    "            c = calculate_containment(df, n, file)\n",
    "            containment_values.append(c)\n",
    "        # Sets value to -1 for original tasks \n",
    "        else:\n",
    "            containment_values.append(-1)\n",
    "    \n",
    "    print(str(n)+'-gram containment features created!')\n",
    "    return containment_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating LCS features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lcs_features(df, column_name='lcs_word'):\n",
    "    \n",
    "    lcs_values = []\n",
    "    \n",
    "    for i in df.index:\n",
    "        if df.loc[i,'Category'] > -1:\n",
    "            answer_text = df.loc[i, 'Text'] \n",
    "            task = df.loc[i, 'Task']\n",
    "            orig_rows = df[(df['Class'] == -1)]\n",
    "            orig_row = orig_rows[(orig_rows['Task'] == task)]\n",
    "            source_text = orig_row['Text'].values[0]\n",
    "\n",
    "            # Calculate lcs\n",
    "            lcs = lcs_norm_word(answer_text, source_text)\n",
    "            lcs_values.append(lcs)\n",
    "        else:\n",
    "            lcs_values.append(-1)\n",
    "\n",
    "    print('LCS features created!')\n",
    "    return lcs_values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram containment features created!\n",
      "2-gram containment features created!\n",
      "3-gram containment features created!\n",
      "4-gram containment features created!\n",
      "5-gram containment features created!\n",
      "6-gram containment features created!\n",
      "7-gram containment features created!\n",
      "8-gram containment features created!\n",
      "9-gram containment features created!\n",
      "10-gram containment features created!\n",
      "11-gram containment features created!\n",
      "12-gram containment features created!\n",
      "13-gram containment features created!\n",
      "14-gram containment features created!\n",
      "LCS features created!\n",
      "\n",
      "Features:  ['c_1', 'c_2', 'c_3', 'c_4', 'c_5', 'c_6', 'c_7', 'c_8', 'c_9', 'c_10', 'c_11', 'c_12', 'c_13', 'c_14', 'lcs_word']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define an ngram range\n",
    "ngram_range = range(1,15)\n",
    "features_list = []\n",
    "\n",
    "all_features = np.zeros((len(ngram_range)+1, len(complete_df)))\n",
    "\n",
    "# Calculate features for containment for ngrams in range\n",
    "i=0\n",
    "for n in ngram_range:\n",
    "    column_name = 'c_'+str(n)\n",
    "    features_list.append(column_name)\n",
    "    # create containment features\n",
    "    all_features[i]=np.squeeze(create_containment_features(complete_df, n))\n",
    "    i+=1\n",
    "\n",
    "# Calculate features for LCS_Norm Words \n",
    "features_list.append('lcs_word')\n",
    "all_features[i]= np.squeeze(create_lcs_features(complete_df))\n",
    "\n",
    "# create a features dataframe\n",
    "features_df = pd.DataFrame(np.transpose(all_features), columns=features_list)\n",
    "\n",
    "# Print all features/columns\n",
    "print()\n",
    "print('Features: ', features_list)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlated Features\n",
    "\n",
    "Our features measure similarity between two texts. However, if features are too highly correlated that will cause most models to overfit on those features. As such, we need to prune features with high correlation values. This is a bit of a dark art, as there do not seem to be any hard rules for what to keep. We will try several iterations of modeling and present the best iteration of features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_1</th>\n",
       "      <th>c_2</th>\n",
       "      <th>c_3</th>\n",
       "      <th>c_4</th>\n",
       "      <th>c_5</th>\n",
       "      <th>c_6</th>\n",
       "      <th>c_7</th>\n",
       "      <th>c_8</th>\n",
       "      <th>c_9</th>\n",
       "      <th>c_10</th>\n",
       "      <th>c_11</th>\n",
       "      <th>c_12</th>\n",
       "      <th>c_13</th>\n",
       "      <th>c_14</th>\n",
       "      <th>lcs_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c_1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_2</th>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_3</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_4</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_5</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_6</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_7</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_8</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_9</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_10</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_11</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_12</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_13</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_14</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcs_word</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           c_1   c_2   c_3   c_4   c_5   c_6   c_7   c_8   c_9  c_10  c_11  \\\n",
       "c_1       1.00  0.94  0.90  0.89  0.88  0.87  0.87  0.87  0.86  0.86  0.86   \n",
       "c_2       0.94  1.00  0.99  0.98  0.97  0.96  0.95  0.94  0.94  0.93  0.92   \n",
       "c_3       0.90  0.99  1.00  1.00  0.99  0.98  0.98  0.97  0.96  0.95  0.95   \n",
       "c_4       0.89  0.98  1.00  1.00  1.00  0.99  0.99  0.98  0.98  0.97  0.97   \n",
       "c_5       0.88  0.97  0.99  1.00  1.00  1.00  1.00  0.99  0.99  0.98  0.98   \n",
       "c_6       0.87  0.96  0.98  0.99  1.00  1.00  1.00  1.00  0.99  0.99  0.99   \n",
       "c_7       0.87  0.95  0.98  0.99  1.00  1.00  1.00  1.00  1.00  1.00  0.99   \n",
       "c_8       0.87  0.94  0.97  0.98  0.99  1.00  1.00  1.00  1.00  1.00  1.00   \n",
       "c_9       0.86  0.94  0.96  0.98  0.99  0.99  1.00  1.00  1.00  1.00  1.00   \n",
       "c_10      0.86  0.93  0.95  0.97  0.98  0.99  1.00  1.00  1.00  1.00  1.00   \n",
       "c_11      0.86  0.92  0.95  0.97  0.98  0.99  0.99  1.00  1.00  1.00  1.00   \n",
       "c_12      0.86  0.92  0.94  0.96  0.97  0.98  0.99  0.99  1.00  1.00  1.00   \n",
       "c_13      0.86  0.91  0.94  0.96  0.97  0.98  0.99  0.99  1.00  1.00  1.00   \n",
       "c_14      0.86  0.91  0.93  0.95  0.97  0.98  0.98  0.99  0.99  1.00  1.00   \n",
       "lcs_word  0.97  0.98  0.97  0.95  0.95  0.94  0.93  0.92  0.91  0.91  0.90   \n",
       "\n",
       "          c_12  c_13  c_14  lcs_word  \n",
       "c_1       0.86  0.86  0.86      0.97  \n",
       "c_2       0.92  0.91  0.91      0.98  \n",
       "c_3       0.94  0.94  0.93      0.97  \n",
       "c_4       0.96  0.96  0.95      0.95  \n",
       "c_5       0.97  0.97  0.97      0.95  \n",
       "c_6       0.98  0.98  0.98      0.94  \n",
       "c_7       0.99  0.99  0.98      0.93  \n",
       "c_8       0.99  0.99  0.99      0.92  \n",
       "c_9       1.00  1.00  0.99      0.91  \n",
       "c_10      1.00  1.00  1.00      0.91  \n",
       "c_11      1.00  1.00  1.00      0.90  \n",
       "c_12      1.00  1.00  1.00      0.90  \n",
       "c_13      1.00  1.00  1.00      0.90  \n",
       "c_14      1.00  1.00  1.00      0.90  \n",
       "lcs_word  0.90  0.90  0.90      1.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = features_df.corr().abs().round(2)\n",
    "display(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiQAAAI4CAYAAABa5/KQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3X2cZHV55/3PdwhKNooMajJGQGKEW8k6I+qKwTtEiSjENcq4gG4UjHllEncVRcmGcbNIcAHjMnKLmkhvQpxBo8gkrg+gSBBEd8Q4KgNC5CHIwqjsxjiIxo1R+rr/qOrusumHqpmqc7q7Pm9f52Wdc+qc61fFzPTV1+/hpKqQJElq06q2GyBJkmRCIkmSWmdCIkmSWmdCIkmSWmdCIkmSWmdCIkmSWmdCIknSGEtycZL/k+Sr85xPkguT3JHkxiRP7Tl3SpLbu9spPcefluSm7jUXJsli7TAhkSRpvL0XOHaB88cBh3S3DcCfAiTZH3gzcATwDODNSVZ3r/nT7nunrlvo/oAJiSRJY62qrgO+s8BbXgRsqY7rgf2SPAZ4PnBVVX2nqnYBVwHHds/tW1Wfr87qq1uAFy/Wjp/a40/SH5eDlSQtF4t2LwzL5L2Hjvzn416Puf136VQrpkxU1cQAt3gscE/P/s7usYWO75zj+IKaSkiYvPfQpkKxas1tABy85a2NxLvr5DMAOOIVb28kHsAXLnkDAM8+9o8bi3ntJ/8AgOc/7c2NxLvyS38EwHEHnNpIPIBP7Lyw0ZhNx+uNecyqExqLedXkZY3GbDpeGzHH4TP2xjx9x0mNxDt/3aWNxGlSN/kYJAGZba4ErXbj+ILsspEkSQvZCRzYs38A8M1Fjh8wx/EFmZBIktSSyQb+NwQfBU7uzrZ5JvDdqvoWcCXwvCSru4NZnwdc2T33vSTP7M6uORn4yGJBGuuykSRJS0+SDwDPBh6VZCedmTN7A1TVe4ArgF8H7gB+APxW99x3krwF+GL3VmdX1dTg2FfTmb3z08AnutuCTEgkSWrJAzWUCsaCFvtBX1UvW+R8Af9xnnMXAxfPcXw78K/7bSPYZSNJkpYAKySSJLVk0lUxplkhkSRJrbNCIklSS4Y0C2ZFsEIiSZJaZ4VEkqSWPFCOIZlihUSSJLXOCokkSS1xls0MKySSJKl1VkgkSWrJA1ZIplkhkSRJrdujhCTJTQuc25Bke5LtExMTexJGkqQVaZIa+bZcLNplk2T9fKeANfNdV1UTwFQmUpP3nj946yRJWsGc9jujnzEklwLvhznTrH2G2xxJkjSO+klIbgTOr6qvzj6R5LnDb5IkSePBheNn9DOG5PXA/fOcO36IbZEkSWNq0QpJVX12gXPbp14n2VhV5w2rYZIkrXRO+50xzGm/JwzxXpIkaYwMc2G0DPFekiSteA9YIJk2zAqJX6skSdotVkgkSWqJs2xm9F0hSbI5yX49+6uTXNzzlsuG2jJJkjQ2BqmQrK2q+6Z2qmpXksN79s8dasskSVrhHrBzYdogY0hWJVk9tZNkf3xasCRJGoJBEopNwLYkW+kMYD0ROGckrZIkaQxMOh1kWt8JSVVtSbIdOJrOANb1VXXLyFomSZLGxkBdLt0ExCREkqQhcAzJjFQzjz62KCVJWi4ayxJuueexI//5eNiB31gWWY+DUiVJaokVkhmNJSQHb3lrU6G46+QzAJi899BG4q1acxsAO+4+sJF4AOsOugeAzbcf2VjMUw7ZBsDpO05qJN756y4F4AXXndpIPIDLj7oQgLUfO7OReDe+8Gygnb8fbcR8/IWbGol356lvBOCJZ13QSDyAr511WqMxp+Kte11zn3HHO9qL2dS/dVP/zql5VkgkSWrJZFkhmTLMZ9lIkiTtFiskkiS1xDEkM6yQSJKk1lkhkSSpJQ9YF5jmNyFJklpnhUSSpJY4y2aGFRJJktQ6KySSJLXEWTYzrJBIkqTWWSGRJKklD5R1gSl+E5IkqXVWSCRJasmkdYFpfhOSJKl1iyYkSQ5M8sEkn03ypiR795z7HwtctyHJ9iTbJyYmhtVeSZJWjAfIyLflop8KycXAtcBrgccAn0nyyO65x813UVVNVNXTq+rpGzZs2OOGSpKklaufMSSPrqr3dF+/NsnLgeuS/AZQo2uaJEkrm7NsZvSTkOydZJ+q+meAqnpfknuBK4GfGWnrJEnSWOgnNfsz4IjeA1X1N8AJwFdH0ShJksbBJBn5tlwsmpBU1QVV9Zk5jn+lqo6Z2k+ycdiNkyRJ42GYnVcnDPFekiSteA+wauTbcjHMli6fupAkSVpShrlSqzNuJEkagLNsZlghkSRJres7IUmyOcl+Pfurk1zc85bLhtoySZJWuElWjXxbLgbpsllbVfdN7VTVriSH9+yfO9SWSZK0wj1Qdi5MGSR1WpVk9dROkv3xacGSJGkIBkkoNgHbkmylM4D1ROCckbRKkqQxsJym5Y5a3wlJVW1Jsh04ms4A1vVVdcvIWiZJksbGQF0u3QTEJESSpCGYdNrvtFQ1snyIa5RIkpaLxkaaXnrHvxn5z8eTnvDFZTFy1kGpkiS1xDEkMxpLSI54xdubCsUXLnkDADvuPrCReOsOugeAyXsPbSQewKo1t7UWs+nvdfPtRzYSD+CUQ7Y1GnMq3uk7TmokHsD56y4F4AXXndpYzMuPuhCAtR87s5F4N77w7Ebj9cY8eMtbG4l318lnNBqvN+bjL9zUWMw7T30j0Nzfkam/H2qeFRJJklriOiQzrBVJkqTWWSGRJKkly2lp91Hzm5AkSa2zQiJJUksecB2SaX4TkiSpdVZIJElqyWRza7AteVZIJElS66yQSJLUEseQzPCbkCRJrbNCIklSS3yWzQy/CUmS1DorJJIktWTSZ9lMs0IiSZJat2hCkuSJST6R5PIkv5jkvUnuS/K3SZ7URCMlSVqJHmDVyLflop+WTgB/ArwP+DTwSWA18BbgXfNdlGRDku1Jtk9MTAyjrZIkaYXqZwzJw6vqYwBJ3lJVH+we/1iSP5rvoqqaoJPMANSff/bte9ZSSZJWmEnXIZnWzzexV8/r2VnFQ4bYFkmSNKb6SUjeneRhAFX1J1MHkzwB+JtRNUySpJXuATLyrR9Jjk1ya5I7kpwxx/nHJbk6yY1Jrk1yQPf4c5Lc0LP9c5IXd8+9N8nXe849ZaE2LJqQVNVFVfX9OY7fUVWv72nsxn4+tCRJWjqS7AW8GzgOOAx4WZLDZr3tfGBLVa0FzgbOA6iqa6rqKVX1FOBo4AfAp3qu+/2p81V1w0LtGGbn1QlDvJckSSveZK0a+daHZwB3VNWdVfUvwAeBF816z2HA1d3X18xxHuDfAZ+oqh/szncxzITE1V0kSVpieme9drcNs97yWOCenv2d3WO9dgAv6b4+Hnh4kkfOes9LgQ/MOnZOt5vngiQPXaidw1yptYZ4L0mSVrx+x3jsiVmzXucyVyNm/0w/HXhXklcC1wHfAH48fYPkMcCTgSt7rtkI3EtnAswE8Ad0unvmNMyExAqJJEnLz07gwJ79A4Bv9r6hqr4JrAfoTnR5SVV9t+ctJwIfrqof9Vzzre7LHyb5CzpJzbz67rJJsjnJfj37q5Nc3POWy/q9lyRJWjJjSL4IHJLkF5I8hE7Xy0d735DkUUmmbrYRuHjWPV7GrO6abtWEJAFeDHx1oUYMMoZkbVXdN7VTVbuAw3v2zx3gXpIkaQmoqh8Dr6HT3fJ3wIeq6uYkZyf5je7bng3cmuQ24OeAc6auT3IwnQrLZ2bd+v1JbgJuAh4F/NeF2jFIl82qJKu7iQhJ9h/wekmS1OOBJbJSa1VdAVwx69iZPa+3AlvnufYuHjwIlqo6epA2DJJQbAK2JdlKZ7DLifRkSJIkSbur74SkqrYk2U5n4ZMA66vqlpG1TJKkFW7S+SDTBupy6SYgJiGSJGmoUtXI8iGuUSJJWi4aK1v8l5uOH/nPx7c8+cPLogyzNEbTSJKksdbYLJlnH/vHTYXi2k/+AQCbbz+ykXinHLINgMl7D20kHsCqNbet+JhT8XbcfeAi7xyedQfd02jMqXhN/VmFmT+vbcQ8fcdJjcQ7f92ljcbrjfmC605tJN7lR13YaLzemGs/duYi7xyeG194dqMxp+I1ZbKWRfGiEU7blSSpJQ/YUTHNb0KSJLXOCokkSS2xy2aGFRJJktQ6KySSJLVk0rrANL8JSZLUOiskkiS15AHHkEyzQiJJklpnhUSSpJY4y2aGFRJJktQ6KySSJLVksqwLTPGbkCRJrbNCIklSSx7AMSRTrJBIkqTW7VaFJMlTq+rLw26MJEnjxFk2MxZNSJI8dfYh4CNJXghkvsQkyQZgA8BFF120p+2UJEkrWD8Vku3A9cAPe449Eng7UMDRc11UVRPAxNTuX/71H+9BMyVJWnmcZTOjn4TkROC1wH+rqisAkny9qp4z0pZJkqSxsWhqVlVbgRcAxyS5LMlBdCojkiRpD0ySkW/LRV+DWqvq+8BpSZ4CbAYeNtJWSZKksTLQLJuquiHJ0cDDZ59LsrGqzhtayyRJWuF82u+MgUfTVMf9c5w6YQjtkSRJY2iYK7Wa5kmSNABn2cwY5jfhQFdJkrRbrJBIktQSV2qd0XeFJMnmJPv17K9OcnHPWy4basskSdLYGKRCsraq7pvaqapdSQ7v2T93qC2TJGmFW07rhIzaIGNIViVZPbWTZH+G2+UjSZLG1CAJxSZgW5KtdAawngicM5JWSZI0BhxDMqPvhKSqtiTZTudhegHWV9UtI2uZJEkaG4Ou1HoLYBIiSdIQuA7JjFQ1snyIa5RIkpaLxvpRTvr874385+Olv/yeZdEv5KBUSZJa4hiSGY0lJM9/2pubCsWVX/ojAE7fcVIj8c5fdykAO+4+sJF4AOsOugeAyXsPbSzmqjW3NRqz6XhtxJyK18afnTZibr79yEbinXLItkbj9cZs+t+dpuK1HXPtx85sJN6NLzy7kTh6MCskkiS1xHVIZjiaRpIktc4KiSRJLXEMyQwrJJIkqXVWSCRJaokVkhlWSCRJUuuskEiS1BIrJDOskEiSpNZZIZEkqSVWSGaYkEiS1BIXRpthl40kSWqdFRJJklpil80MKySSJKl1VkgkSWqJFZIZi1ZIkryq5/UBSa5Ocl+SbUnmfUZ7kg1JtifZPjExMaz2SpKkFaifLpvX9Lx+O/AhYH/gvwF/Ot9FVTVRVU+vqqdv2LBhz1opSdIKNFkZ+bZcDDqG5NCquqiqJqvqw3QSE0mSpD3SzxiSA5JcCAR4dJK9q+pH3XN7j65pkiStbMupgjFq/SQkv9/zejvwMGBXkjXAR0fSKkmSNFYWTUiqavM8x+8F3jS1n2RjVZ03xLZJkrSilRWSacNch+SEId5LkiSNkWGuQ2KaJ0nSAHyWzYxhVkhqiPeSJEljxAqJJEktcZbNjL4rJEk2J9mvZ391kot73nLZUFsmSZLGxiAVkrVVdd/UTlXtSnJ4z/65Q22ZJEkrnLNsZgwyhmRVktVTO0n2x4fzSZKkIRgkodgEbEuylc4A1hOBc0bSKkmSxoBjSGb0nZBU1ZYk24Gj6QxgXV9Vt4ysZZIkaWwM1OXSTUBMQiRJGgLHkMxIVSPLh7hGiSRpuWgsS3jmlRtH/vPx+ueftyyyHgelSpLUEseQzGgsITnugFObCsUndl4IwAuuaybm5Ud14m2+/chG4gGccsg2AHbcfWBjMdcddA8Ak/ce2ki8VWtuazReGzHb/Ixt/NlpKmbT8XpjNvXvwNS/AW38u9NGzIO3vLWReHedfEYjcfRgVkgkSWpJM6MmlodhPstGkiRpt1ghkSSpJT7td4YVEkmS1DorJJIktcR1SGZYIZEkSa2zQiJJUktch2SGFRJJksZckmOT3JrkjiQPWowlyeOSXJ3kxiTXJjmg59wDSW7obh/tOf4LSb6Q5PYklyZ5yEJtMCGRJKklVaPfFpNkL+DdwHHAYcDLkhw2623nA1uqai1wNnBez7n/W1VP6W6/0XP8j4ELquoQYBfw2wu1w4REkqTx9gzgjqq6s6r+Bfgg8KJZ7zkMuLr7+po5zv+EJAGOBrZ2D20GXrzQNSYkkiS1pCoj35JsSLK9Z9swqxmPBe7p2d/ZPdZrB/CS7uvjgYcneWR3f5/ufa9PMpV0PBK4r6p+vMA9f4KDWiVJWsGqagKYWOAtc42snd3ZczrwriSvBK4DvgFMJRsHVdU3kzwe+HSSm4D7+7jnTzAhkSSpJUtkHZKdQO+TKA8Avtn7hqr6JrAeIMnDgJdU1Xd7zlFVdya5Fjgc+CtgvyQ/1a2SPOiesw3cZZNk3yRPS7J60GslSdKS80XgkO6smIcALwU+2vuGJI9KMpUzbAQu7h5fneShU+8BngXcUlVFZ6zJv+tecwrwkYUasWhCkuR93SAkeT5wM52RszckOaGfTypJkh5ssjLybTHdCsZrgCuBvwM+VFU3Jzk7ydSsmWcDtya5Dfg54Jzu8ScB25PsoJOAvLWqbume+wPgDUnuoDOm5M8Xakc/XTbrqurb3ddvBn6lqu7qJilXA5fNdVF30MwGgIsuuqiPMJIkqQ1VdQVwxaxjZ/a83srMjJne92wDnjzPPe+kM4OnL/0kJKuS7FtV9wOTwN3dQN9OMu/1swbR1IfPPrXfNkmSNBb6WSdkXPSTkPwRcE2SdwP/E7gsyUfozC/+5CgbJ0mSxsOiCUlVfSjJl4HfAQ7tXvPLwAeq6soRt0+SpBVricyyWRL6mvZbVXfQGZwyryQbq+q8hd4jSZJmmJDMGOZKrc64kSRJu2WYC6OZ5kmSNADHtM4YZoXE71WSJO0WKySSJLXEMSQz+q6QJNmcZL+e/dVJLu55y5wLpEmSJC1mkArJ2qq6b2qnqnYlObxn/9yhtkySpJXOwQ7TBhlDsqr3gXpJ9senBUuSpCEYJKHYBGxLspVOTnciMw/XkSRJA3IMyYy+E5Kq2pJkO50l4wOs73minyRJ0m4bqMulm4CYhEiSNAQ+XG9Gqplvw69ckrRcNNaP8oQP/deR/3y848Q/XBb9Qg5KlSSpJY4hmdFYQnLcAac2FYpP7LwQgLUfO7OReDe+8GwANt9+ZCPxAE45ZBsAO+4+sLGY6w66B4DJew9tJN6qNbc1Gq+NmOPwGduIORWvjb8fTcVsOl5vzDb+rXv8hZsaiXfnqW9sJI4ezAqJJEltsUIybZjPspEkSdotVkgkSWqJs2xmWCGRJEmts0IiSVJbrJBMs0IiSZJaZ4VEkqSWuA7JDCskkiSpdVZIJElqi2NIplkhkSRJrbNCIklSSxxDMsMKiSRJap0VEkmS2uIYkmlWSCRJUuuskEiS1BrHkExZtEKS5DtJ/izJryXp+5tLsiHJ9iTbJyYm9qyVkiRpReuny+YfgBuAs4GdSd6R5JmLXVRVE1X19Kp6+oYNG/a0nZIkrTzVwLZM9JOQ/FNVvauqngX8MvAN4E+S3Jnk3NE2T5IkjYN+EpLpbpqquruq3lZVTwWOA344spZJkrTSWSGZ1s+g1mvmOlhVtwJ/NNzmSJKkcbRohaSq3tDPjZJs3PPmSJI0Riqj35aJYa5DcsIQ7yVJksbIMNchWT5pmCRJS0AtozEeozbMColfqyRJ2i1WSCRJaou/yk/ru0KSZHOS/Xr2Vye5uOctlw21ZZIkaWwMUiFZW1X3Te1U1a4kh/fsu0iaJEmDWEazYEZtkIRkVZLVVbULIMn+A14vSZJ6xC6baYMkFJuAbUm20un1OhE4ZyStkiRJY6XvhKSqtiTZDhxNZwDr+qq6ZWQtkyRppbNCMm2gLpduAmISIkmShirVzKos5oCSpOWisZGmB190/sh/Pt71u6cvi5Gzw1wYTZIkabc0NkvmuANObSoUn9h5IQAHb3lrI/HuOvkMAE7fcVIj8QDOX3cpAJtvP7KxmKccsg2AHXcf2Ei8dQfdA8DkvYc2Eg9g1ZrbGo3ZdLxxidnmZ2z670dT8dqO+cSzLmgk3tfOOq2RONPsP5hmhUSSJLXOdUQkSWqLFZJpVkgkSVLrrJBIktQWKyTTrJBIkqTWWSGRJKktPlxvmhUSSZLUOiskkiS1xKf9zrBCIkmSWmeFRJKktlghmWaFRJIktc6ERJIktc6ERJIktW63xpAkeVRVfXvYjZEkaZw4y2bGohWSJMcl+XqSzyU5PMnNwBeS7EzyawtctyHJ9iTbJyYmhtpoSZK0svRTITkP+HVgP+BvgBdU1fVJngS8H3jqXBdV1QQwlYnUh88+dQjNlSRpBXGl1mn9JCSTVfV3AEl+UFXXA1TV3yVxDIokSdpj/SQk9yX5XWBfYFeS04APAc8Fvj/KxkmStKI5hmRaPxWOU+h0yzweeF732JXAicDvjKhdkiRpjCxaIamqe4Df7Tl0QXf7CUk2VtV5Q2ybJEkrmxWSacMcA3LCEO8lSZLGyDCfZeNQYUmSBuA6JDOGWSHxa5UkSbvFCokkSW3xV/lpfVdIkmxOsl/P/uokF/e85bKhtkySJI2NQSoka6vqvqmdqtqV5PCe/XOH2jJJklY6KyTTBhlDsirJ6qmdJPsz3C4fSZI0pgZJKDYB25JspZPTnQicM5JWSZI0BpxlM6PvhKSqtiTZDhxNZwDr+qq6ZWQtkyRJY2Ogab9VdUtVvauq3mkyIknSHqqMfutDkmOT3JrkjiRnzHH+cUmuTnJjkmuTHNA9/pQkn09yc/fcST3XvDfJ15Pc0N2esmAbqhqpF1mUkiQtF40tY/GEt10w8p+Pd/yn0xb8PEn2Am4DjgF2Al8EXtZbeEhyGfDxqtqc5Gjgt6rqFUkOBaqqbk/y88CXgCdV1X1J3tu9Zms/7RzmwmiSJGkQ1cC2uGcAd1TVnVX1L8AHgRfNes9hwNXd19dMna+q26rq9u7rbwL/B3h0/1/AjMZmyRyzqrlH3Vw12VkS5eAtb20k3l0nd6pbL7ju1EbiAVx+1IUAbL79yMZinnLINgB23H1gI/HWHXRPo/F6Y07ee2gj8Vatua3ReOMS08842pht/J1c97oHPdN1JHa847RG4jQpyQZgQ8+hiaqa6Nl/LHBPz/5O4IhZt9kBvAR4B3A88PAkj6yqf+yJ8wzgIcDf91x3TpIz6SQzZ1TVD+drpxUSSZJakhr9VlUTVfX0nm1idjPmaNrs2srpwK8m+Qrwq8A3gB9P3yB5DHAJna6cye7hjcATgX8D7A/8wULfheuISJI03nYCvWWvA4Bv9r6h2x2zHiDJw4CXVNV3u/v7ApcDf1hV1/dc863uyx8m+Qs6Sc28rJBIktSWpTGG5IvAIUl+IclDgJcCH+19Q5JHJZnKGTYCF3ePPwT4MLClqi6bdc1juv8f4MXAVxdqhAmJJEktaaLLZjFV9WPgNcCVwN8BH6qqm5OcneQ3um97NnBrktuAn2NmYdQTgaOAV84xvff9SW4CbgIeBfzXhdphl40kSWOuqq4Arph17Mye11uBB03frar3Ae+b555HD9IGExJJktriKl3T7LKRJEmts0IiSVJbrJBMs0IiSZJaZ4VEkqSW9DMLZlxYIZEkSa0zIZEkSa0zIZEkSa0baAxJktXAj6vqeyNqjyRJ48MxJNMWrZAk+fkkW5J8F/g2cHOSu5OclWTv0TdRkiStdP102bwPuLiqHgGcAPwV8CQ61ZV3z3dRkg1JtifZPjEx+0nHkiRpKTzLZqnop8vmkVV1LUBV/XWS/1xV/wT8YZKvzXdRVU0AU5lIXfZ7V+1xYyVJ0srUT0LyD0leDnwaeAlwF0w/TthBsZIk7a5lVMEYtX4SilcBvwF8CjiCziOKAfYHNo6oXZIkaYwsWiGpqruBE+c4/o90xpMAkGRjVZ033OZJkrSCWSGZNswulxOGeC9JkjRGhvksmwzxXpIkrXjLaRbMqA2zQuLXKkmSdosVEkmS2uKv8tP6rpAk2Zxkv5791Uku7nnLZUNtmSRJGhuDVEjWVtV9UztVtSvJ4T375w61ZZIkrXCOIZkxyBiSVd2H6wGQZH+G2+UjSZLG1CAJxSZgW5KtdHq9TgTOGUmrJEkaB1ZIpvWdkFTVliTbgaPpDGBdX1W3jKxlkiRpbAzU5dJNQExCJEkaBisk01LVyLfhVy5JWi4aW8bisDddMPKfj7ece9qyWJbDQamSJLXEWTYzGktIjlnV3KNurprsLIny+As3NRLvzlPfCMDaj53ZSDyAG194NgCn7zipsZjnr7sUgM23H9lIvFMO2QbAjrsPbCQewLqD7gFg8t5DG4m3as1tjcYbl5h+xpUXc93rLmgk3o53nNZIHD2YFRJJktpihWTaMJ9lI0mStFuskEiS1BYrJNOskEiSpNZZIZEkqSXOsplhhUSSJLXOCokkSW2xQjLNCokkSWqdFRJJklriGJIZVkgkSVLrrJBIktQWKyTTTEgkSWqLCck0u2wkSVLrrJBIktSStN2AJaSvhCTJI4BjgcfSKTB9E7iyqu4bYdskSdKYWLTLJsnJwJeBZwP/CvgZ4DnAl7rn5rtuQ5LtSbZPTEwMqbmSJK0g1cC2TPRTIfnPwNNmV0OSrAa+AGyZ66KqmgCmMpG67Peu2pN2SpKkFayfhCTMnWNNYveXJEm7zYXRZvSTkJwDfDnJp4B7uscOAo4B3jKqhkmSpPGx6BiSqtoMPB34DPBD4F+Aa4GnV9V7R9k4SZJWNMeQTOtrlk1V7QI+OOK2SJKkMbVHC6MluWlYDZEkaexYIZm2aIUkyfr5TgFrhtscSZI0jvrpsrkUeD9z51n7DLc5kiSND2fZzOgnIbkROL+qvjr7RJLnDr9JkiRp3PSTkLweuH+ec8cPsS2SJI0XKyTT+pn2+9mqunuec9unXifZOMyGSZKk8bFHs2xmOWGI95IkacVLjX5bLoaZkLiMvCRJ2i19LYzWp2WUh0mStAT4k3OaFRJJktS6VPWXniXZDLyuqu7r7q8GNlXVq7r7b6qqc+e53BxQkrRcNPYL9lNffcHIfz5++U9PWxYFg0EqJGunkhGYfr7N4T378yUjkiRJCxpkDMmqJKu7iQhJ9h/k+mNWNTcJ56rJywB44lkXNBLva2edBsDaj53ZSDyAG1/C4IX2AAAcnUlEQVR4NgCn7zipsZjnr7sUgM23H9lIvFMO2QbAjrsPbCQewLqD7mk05lS8yXsPbSQewKo1t634mH7GlRfziFe8vZF4X7jkDY3EmWb/wbRBEpJNwLYkW+l8hScC54ykVZIkaaz0nZBU1ZYk24Gj6fSvra+qW0bWMkmSVjorJNMGmvbbTUBMQiRJ0lANcx0SSZI0gOW0kuqoDXMdEkmSpN1ihUSSpLZYIZlmhUSSJLXOCokkSS1Jn6uljwMrJJIkqXVWSCRJaosFkmlWSCRJUuuskEiS1BLXIZlhhUSSJLXOCokkSW2xQjJtjyokSY4ZVkMkSdL42tMKyZ8DB811IskGYAPARRddtIdhJElaeRxDMmPRhCTJR+c7BTxyvuuqagKYmNq97PeuGrx1kiRpLPRTIfkV4OXA92cdD/CMobdIkqRxYYVkWj9jSK4HflBVn5m1XQvcOtrmSZKkUUtybJJbk9yR5Iw5zj8uydVJbkxybZIDes6dkuT27nZKz/GnJbmpe88Lk2ShNiyakFTVcVV1zTznjlrsekmSNLfU6LdF25DsBbwbOA44DHhZksNmve18YEtVrQXOBs7rXrs/8GbgCDq9Jm9Osrp7zZ/SGUt6SHc7dqF2uA6JJEltqQa2xT0DuKOq7qyqfwE+CLxo1nsOA67uvr6m5/zzgauq6jtVtQu4Cjg2yWOAfavq81VVwBbgxQs1Yk+n/d60J9dLkqTWPRa4p2d/Z/dYrx3AS7qvjwcenuSRC1z72O7rhe75E/qZZbN+vlPAmsWulyRJc2ti2m/vMhxdE92ZsNNvmeOy2S07HXhXklcC1wHfAH68wLX93PMn9DPL5lLg/fPcaJ8+rpckSS2ZtQzHXHYCB/bsHwB8c9Y9vgmsB0jyMOAlVfXdJDuBZ8+69truPQ+Ydfwn7jlbPwnJjcD5VfXV2SeSPLeP6yVJ0lxqScz7/SJwSJJfoFP5eCnw73vfkORRwHeqahLYCFzcPXUlcG7PQNbnARur6jtJvpfkmcAXgJOBdy7UiH7GkLweuH+ec8f3cb0kSVqiqurHwGvoJBd/B3yoqm5OcnaS3+i+7dnArUluA34OOKd77XeAt9BJar4InN09BvBq4M+AO4C/Bz6xUDsWrZBU1WcXOLd96nWSjVV13mL3kyRJHUtl6fiqugK4YtaxM3tebwW2znPtxcxUTHqPbwf+db9tGOa03xOGeC9JkjRG9vTher0WXIFNkiTNskQqJEvBMCskfq2SJGm3pIY0wjfJV6rq8HlOm6xIkpaLxir+R560aeQ/H7dd+sZl0YPRd4UkyeYk+/Xsr07SO4jlsqG2TJIkjY1BxpCsrar7pnaqaleSw3v2z13o4mNWNTfm9arJTm70xLMuaCTe1846DYCDt7y1kXgAd53ceRjjC647tbGYlx91IQCn7zipkXjnr7sUgM23H9lIPIBTDtkGwI67D1zkncOx7qB7Go3XG3Py3kMbi7lqzW2Nxmw6Xhsxx+Ez9sY84hVvbyTeFy55QyNxptl/MG2QMSSrehY+mXrC3zAHxUqSpDE1SEKxCdiWZCudnO5EugujSJKkwS2VdUiWgr4TkqrakmQ7cDSdAT/rq+qWkbVMkiSNjYG6XLoJiEmIJEnDsDSeZbMkDHMdEkmSpN3ioFRJklriGJIZVkgkSVLrrJBIktQWKyTTrJBIkqTWWSGRJKkljiGZYYVEkiS1zgqJJEltcR2SaVZIJElS66yQSJLUEseQzOirQpJk3yS/OMfxtcNvkiRJGjeLJiRJTgS+BvxVkpuT/Jue0+9d4LoNSbYn2T4xMbHnLZUkaaWpBrZlop8KyZuAp1XVU4DfAi5Jsr57LvNdVFUTVfX0qnr6hg0bhtBUSZK0UvUzhmSvqvoWQFX9bZLnAB9PcgDLKveSJGlpcQzJjH4qJN/rHT/STU6eDbwI+KURtUuSJI2Rfiokr2ZW10xVfS/JscCJI2mVJEnjYNISyZRFE5Kq2jHP8R8B7x96iyRJ0tjZo4XRktw0rIZIkjR2nGUzbdEKSc+MmgedAtYMtzmSJGkc9TOG5FI6XTNz5Vn7DLc5kiSND2fZzOgnIbkROL+qvjr7RJLnDr9JkiRp3PSTkLweuH+ec8cPsS2SJI0Xn/Y7bdFBrVX12aq6e55z26deJ9k4zIZJkqTxsUezbGY5YYj3kiRpxUuNflsuhpmQzPtcG0mSpIX0M4akX8soD5MkaQnwJ+e0YSYkVkgkSRpAHNQ6LdXnl5FkM/C6qrqvu78a2FRVr+ruv6mqzp3ncr9xSdJy0dgv2Ecf89aR/3z89FVnLIuCwSAVkrVTyQhAVe1KcnjP/nzJiCRJmstk2w1YOgZJSFYlWV1VuwCS7D/I9cesam4SzlWTlwGw7nUXNBJvxztOA+DgLW9tJB7AXSefAcALrju1sZiXH3UhAKfvOKmReOevuxSAzbcf2Ug8gFMO2QbAjrsPbCTeuoPuaTReb8zJew9tLOaqNbc1GrPpeG3EHIfP2BvziFe8vZF4X7jkDY3E0YMNkpBsArYl2UqnC+ZE4JyRtEqSpDHgGJIZfSckVbUlyXbgaDr9a+ur6paRtUySJI2NgWbZdBMQkxBJkobBAsm0YS6MJkmStFuGuQ6JJEkahGNIplkhkSRJrbNCIklSS5bTw+9GzQqJJElqnRUSSZLa4hiSaVZIJElS66yQSJLUkvgsm2lWSCRJUuuskEiS1BbHkEzrq0KSZE2SNd3Xj06yPskvjbZpkiRpXCyakCT5XeDzwPVJXg18HPi3wF8n+e0FrtuQZHuS7RMTE0NrsCRJK0Y1sC0T/XTZvAb4JeCngf8FPKGq7k2yGrgG+PO5LqqqCWAqE6nLfu+qITRXkiStRP0kJD+qqh8AP0jy91V1L0BV7UpcY06SpN0Vx5BM62cMyWSSvbuvXzB1MMk+fV4vSZK0oH4qJOvp9kJV1c6e448E3jiKRkmSNBaskExbNCGpqrvnOf4N4BtDb5EkSRo7e9TlkuSmYTVEkqSxM9nAtkwsWiFJsn6+U8Ca4TZHkiSNo37GkFwKvJ+5ZzPvM9zmSJI0PpxlM6OfhORG4Pyq+ursE0meO/wmSZKkcdNPQvJ64P55zh0/xLZIkjRerJBMW3RQa1V9doGZNtunXifZOMyGSZKk8THMhc1OGOK9JEla+apGvy0Tw0xIMsR7SZKkMdLPGJJ+LZ80TJKkpWAZrRMyalZIJElS61J99i8l2Qy8rqru6+6vBjZV1au6+2+qqnPnudzqiSRpuWjsF+xjn3LmyH8+fvKGs5dFwWCQCsnaqWQEoKp2AYf37M+XjEiSJC1okDEkq5Ks7iYiJNl/kOuPWdXcJJyrJi8DYN3rLmgk3o53nAbA4y/c1Eg8gDtP7Txoee3Hzmws5o0vPBuA03ec1Ei889ddCsDm249sJB7AKYdsazTmVLwddx/YSDyAdQfd01rMyXsPbSTeqjW3NRqvjZjj8Bl7Yx7xirc3Eu8Ll7yhkTjTltEsmFEbJCHZBGxLspVOF8yJwDkjaZUkSRorfSckVbUlyXbgaDr9a+ur6paRtUySpJXOCsm0gab9dhMQkxBJkjRUw1yHRJIkDcIKyTQTEkmS2uLCaNOGuTCaJEnSbrFCIklSS2KXzTQrJJIkqXUmJJIktaVq9Fsfkhyb5NYkdyQ5Y47zByW5JslXktyY5Ne7x38zyQ0922SSp3TPXdu959S5n12oDXbZSJI0xpLsBbwbOAbYCXwxyUdnrTX2h8CHqupPkxwGXAEcXFXvB97fvc+TgY9U1Q091/1mVW3vpx0mJJIktWVySYwheQZwR1XdCZDkg8CL+Ml1xwrYt/v6EcA357jPy4AP7G4j7LKRJGkFS7IhyfaebcOstzwWuKdnf2f3WK+zgJcn2UmnOvLaOUKdxIMTkr/odtf8lyQLPnXYCokkSW1pYJZNVU0AEwu8Za5EYXbDXga8t6o2Jfll4JIk/7qqJgGSHAH8oKq+2nPNb1bVN5I8HPgr4BXAlvkasVsVkiTn7s51kiRpydkJ9D7++wAe3CXz28CHAKrq88A+wKN6zr+UWdWRqvpG9/+/B/wlna6heS1aIUly4exDwCuSPKwb6NTF7iFJkuawNNYh+SJwSJJfAL5BJ7n497Peczfwa8B7kzyJTkLyDwBJVgEnAEdNvTnJTwH7VdW3k+wN/FvgbxZqRD9dNuuBa4FPMVPWeSnwpYUu6vZRbQC46KKL+ggjSZKaVlU/TvIa4EpgL+Diqro5ydnA9qr6KPBG4L8nOY1Od84rq6azqaOAnVODYrseClzZTUb2opOM/PeF2tFPQvIk4C3AscDvd/uD3lxVmxf5gL19VnXZ713VRyhJksbI0qiQUFVX0Bms2nvszJ7XtwDPmufaa4Fnzjr2T8DTBmnDoglJt+/n9UmeBrwvyeU4O0eSJA1R34lFVX0JOBr4v8DnRtYiSZLGxWSNflsmBqp0VMe7q+rlo2qQJEkaP3u0DkmSm6rqycNqjCRJY6WzjIfob9rv+vlOAWuG2xxJkjSO+qmQXErnwTlzdUTtM9zmSJI0RpbILJuloJ+E5Ebg/FnLwQKQ5LnDb5IkSRo3/SQkrwfun+fc8UNsiyRJ42UZzYIZtUVn2VTVZ6vq7nnObZ96nWTjMBsmSZLGxzAXODthiPeSJGnlqxr9tkwMMyGZ6/HFkiRJi9qjdUhmWT5pmCRJS8EyqmCMmhUSSZLUulSf2VmSzcDrquq+7v5qYFNVvaq7/6aqOneey00BJUnLRWO/YB/32NeO/OfjJ77xzmVRMBikQrJ2KhkBqKpdwOE9+/MlI5IkSQsaZAzJqiSru4kISfYf5PrTd5w0aNt22/nrLgVg8+1HNhLvlEO2Ae18xrUfO7OxmDe+8OxGY07FO3jLWxuJB3DXyWcA8PgLNzUS785T3wjAE8+6oJF4AF876zQA1r2uuZg73tFszKl4R7zi7Y3EA/jCJW9oNGbT8dqOOXnvoY3EW7XmtkbiTJv0WTZTBklINgHbkmyl0wVzInDOSFolSZLGSt8JSVVtSbIdOJpO/9r6qrplZC2TJGmlc5bNtIGm/XYTEJMQSZI0VMNch0SSJA3CCsm0Ya5DIkmStFuskEiS1Baf9jvNCokkSWqdFRJJklpS5TokU6yQSJKk1lkhkSSpLY4hmWaFRJIktc4KiSRJbXEdkmlWSCRJUuuskEiS1Baf9jtt0YQkyfqFzlfVXw+vOZIkjRG7bKb1UyF5Yff/fxY4Evh0d/85wLXAnAlJkg3ABoCLLroIjtijdkqSpBVs0YSkqn4LIMnHgcOq6lvd/ccA717guglgYmr39B1X73lrJUlaQcoum2mDDGo9eCoZ6frfwKFDbo8kSRpDgwxqvTbJlcAHgAJeClwzklZJkjQOHEMyre+EpKpek+R44KjuoYmq+vBomiVJksZJXwlJkr2AK6vquYBJiCRJw+DS8dP6GkNSVQ8AP0jyiBG3R5IkjaFBxpD8M3BTkquAf5o6WFWnDr1VkiSNg3KWzZRBEpLLu5skSdJQDTKodXOShzAz1ffWqvrRaJolSdLKV44hmdZ3QpLk2cBm4C4gwIFJTqmq60bTNEmSNC4G6bLZBDyvqm4FSHIonTVJnjaKhkmStOI5hmTaICu17j2VjABU1W3A3sNvkiRJGjeDVEi2J/lz4JLu/m8CXxp+kyRJGg+OIZkxSELyauA/AqfSGUNyHfAno2iUJEkaL4MkJM8C3lNVbx9VYyRJGiuOIZmW6vPBPkm2AM8E/hH4bHf7XFXt6uNya1KSpOUiTQU6ZtUJI//5eNXkZY19nj1SVQNtwM/T6ba5G/jxoNcPGGvDKO8/rjH9jMZcLvHGJaafceXEdNv9re9ZNklenuQiYCvwXOBdwK/sVhbUvw0jvv+4xvQzGnO5xBuXmH7GlRNTu2mQMST/H/D3wHuAa6rqrpG0SJIkjZ2+KyRV9SjgVcA+wDlJ/jbJJYtcJkmStKhBumz2BQ4CHgccDDwCGPXw4IkR339cY/oZjblc4o1LTD/jyomp3TTILJsbgc91t+uqaucoGyZJksZH3wnJojdK3llVrx3KzSRJ0lgZ5Fk2i3nWEO8lSZLGyDATEkmSpN1iQjKGkjy17TaMUpJ9kzwtyeq22zJqSR7VUJzVSR7eUKxHJDkpyRuSnNZ9vV8TsVeyJGuSrOm+fnSS9Ul+qcH45zYVS8vTMBOSkS1Nm+SmEd33wCQfTPLZJG9KsnfPuf8xophPTPKJJJcn+cUk701yX3ca9ZNGEO+ps7anAR9NcvioEpMkr+p5fUCSq7ufcVuSQ0cQ731TP5iTPB+4Gfhj4IYkJww7XjfOd5L8WZJfS9LIssxJjkvy9SSf6/73uxn4QpKdSX5tBPF+PsmWJN8Fvg3cnOTuJGf1/l0ZcsyTgS8Dzwb+FfAzwHOAL3XPNSbJMSO8975JfnGO42tHFO93gc8D1yd5NfBx4N8Cf53kt0cQ78JZ2zuB/zC1P+x43ZjrF9pGEVPDtVuDWpOsAh5WVff3HHtlVb13txsy/x+Y0Hmo36N3994LxLwK+CvgeuC3gacBL6yqf0zylao6fAQxrwP+G/Aw4K3AHwCX0vnH4fVVNdQfLEkm6Xy+H/Ycfmb3WFXV0cOM14355ap6avf1h4Crgf8OvAh4zQg+401V9eTu623Av6+qu7pJytVVtW6Y8bpxbgXeCbyMzjT4rcAHqur6YcfqiXlDN95+dH6gvKCqru8msu+f+s6HGO/TwNlVdW337+evAH8IbAR+tqqGvgpm93s9oqrum3V8NfCFqhp6QrtAW+6uqoNGcN8T6Sw0+X+AvYFXVtUXu+e+POz/jt373gQcAfw08L+AJ1TVvd3v9ZqqesqQ4+0ErgU+xcwvq+cDpwNU1eZhxuvG/Ivuy58FjgQ+3d1/DnBtVZmULHX9rjEP/CWwL53fWL4GfAv4/WGtYQ/8CHgv8BdzbN8bxbr5wA2z9l9O57frXwS+PKKYX+l5fcesc0OPCfw74DPAr/cc+/ooPttcn2OO7/grI4h3M7Bv9/XngFW95xr4jAcB/4nOb/Z3Auc2EPOeWeduGEG8HbP2v9Tz+msj+oy3AY+Y4/gjgNtHEO+j82wfA/5pRJ/xBuAx3dfP6P57ur67P/S/H3P82Zn933UUfycfTifp+kvgsd1jd47is80R++NT3293/zHAXzcR223PtkGWjj+squ5P8pvAFXR+s/8Snd/2h+FG4Pyq+ursE0meO6QYs+2dZJ+q+meAqnpfknuBK+kkXqOwV8/rt88695BhB6uqrUk+CbwlyW8Bb2T0T18+oFuWDfDoJHtX1Y+650ZR6v8j4Jok7wb+J3BZko8ARwOfHEE86OmirKq7gbcBb0vy/wAvHVHM+7ql932BXUlOAz5E59lS3x9BvH9I8nI6v2m+BLgLoNtFNarxZ+cAX07yKeCe7rGDgGOAt4wg3q/Q+UVk9vcXOsnCKOxVVd8CqKq/TfIc4ONJDmB0fzcne/4evmDqYJJ9GMF/y6r6HvD6bhfx+5JcPoo48zh46vvt+t9AY5U17b5BEpK9u/3GLwbeVVU/SjLMvzyvB+6f59zxQ4zT68/olDE/M3Wgqv6mO+7gbSOK+e4kD6uq71fVn0wdTPIE4G9GEbCqvg+cluQpwGY63UWj9Ps9r7d34+1KZ0DdR4cdrKo+lOTLwO/Q+Yfnp4BfptOFcuWw43VdM09bbqWTII3CKXS6TCaB59HpvrmSTgn+d0YQ71V0yuxn0Pmt/jXd4/vT6bYZuqranOSjwPOBx9JJDK4FNlbVrhGEvB74QVV9ZvaJbvfRKHwvyS9W1d8DVNW3kjwb+B/AqAaZrqeb7NRPLmr5SDq/pIxEVX0pydHAf6BTvWzCtUmuBD5A5zO/lHn+vmppGWSl1lPpVEV20MmwDwLeV1WjfuLv7HZsrKrzjLnb9w3w8OoZ/zPKeIu0pdGY4/AZ24jZxmdczpKso9MddMes43sDJ1bV+9tp2cqR5HjgqO7udVX14Tbbo/7s9kqt3R9se1XVj4fbpEXjjmTQ17jH9DMac6nH6x28rOFp+nsdZbwkewFXVtWouvk1Qn132aQzh/xtNTP6fT86pb4/HEXDFmpKw/HGJaaf0Zitx1tktt2aYcXpsy2NJ0Cjitn099rWf8eqeiDJD5I8oqq+O6o4Go1BxpAcV1Vvmtqpql1Jfp3mE5JRD8gc15h+RmMuhXiXAu+f5577DDEO0M4PzpZ+WDf6vbYQr9c/Azd1l3X4p6mDVXXqiONqDw2SkOyV5KFV9UOAJD8NPHQ0zVrQOPzG2UZMP6Mxl0K8pmfbtfGDs42YTX+vbcyanHJ5d9MyM8g0rPcBVyf57XRW4ryKzoyNoUqyOT3LRKezZPXFPW+5zJhLP14bMcfhM7YRs+F4Tc+2m/rB+VuzN+C+xS5eRjGb/l7bmDUJTC+69gE6y1J8CfjLGsFCbBqBQRYtAY6jMw1wE/D8USyMwhyL9Mx1zJhLO56fceXEbOMz9tGmjUO6z68AB81z7ukjanvjMZv+XtuMR+exA/+LznIO1wFfB45q83t1628baKGaqvpEVZ1eVW+s0a3vsCo9D0VLsj+DdS0Zc2nEayPmOHzGNmK28RkXM5RnFFXVZ6uzsN1c57ZPvU4ytHVX2og5gJE8+6nheJuA51XVr1bVUXTWtLlgBHE0ZIv+o5Lke8zd1xk6z0LZd8ht2gRsS7K1G/dEOqs3jtI4xPQzGnO5xOtH0+NkTgCaXmuljZjLefzRlL2rs0AhAFV1W0b0MEgN126vQzJKSQ6js+x36Dwc7RZjLr94bcQch8/YRsw2PuMi7Wl6rZWRPGxzCcZc9mvYdMc3FXBJ99BvAj9VnTE6WsKWZEIiSQtp+of1OCxw143Z9Pc69HhJHgr8R+D/pZNAXwf8SXVniGrpauphR5LUtzZmLy3WpIbjjSTmCp+hNeVZwHuqan1VHV9VF5iMLA8mJJKWorU1syo01Xmw3uE9++cOM9g4TN/uavR7bSEewCuBG5J8Psnbkrywd1C2li4TEklLUdMze9r4wdlGzBU/Q6uqTq6qQ4GXADuBdwP/MMqYGo62p+5J0lyantmzKsnqblLQ6PTthmOu+BlaSV5OZ62XJwPfBt4FfHaUMTUcDmqVtCQ1ObMnycnARuAnfnBW1SULXrjMYnbjrugZWkm+Dfw98B7gmqq6a5TxNDwmJJLEeEzfHhdJfgk4is5Mm0OAW6vqFe22Souxy0aSgG4y0GhC0EbMlS7JvsBBwOOAg4FHAJNttkn9sUIiSVoxktwIfK67XVdVO1tukvpkQiJJGhtJ3llVr227HXowp/1KksbJs9pugOZmQiJJklpnQiJJklpnQiJJGidtPJdIfTAhkSStSElWdacB93pHK43RokxIJEkrRpK/TLJvkp+hs8bLrUl+f+p8Vb23tcZpQSYkkqSV5LCquh94MXAFnUXSXKV1GTAhkSStJHsn2ZtOQvKRqvoRnWcFaYkzIZEkrSQXAXcBPwNcl+RxwP2ttkh9caVWSdKKlSTAXlX147bbooVZIZEkrRhJzk2yX8+h/YCzWmqOBmBCIklaSY6rqvumdqpqF/DrLbZHfTIhkSStJHsleejUTpKfBh66wPu1RPxU2w2QJGmI3gdcneQv6MyueRWwud0mqR8OapUkrShJjgN+jc4y8Z+qqitbbpL6YEIiSZJaZ5eNJGnZS/I95l4ALUBV1exn2miJsUIiSZJa5ywbSZLUOhMSSZLUOhMSSZLUOhMSSZLUuv8fgqxT5yKERWIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "sns.heatmap(corr_matrix, cmap='viridis',linewidths=1)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep c1, c2, c3, c4, and lcs_wrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_data(complete_df, features_df, selected_features):\n",
    "    '''\n",
    "    Gets selected training and test features from given dataframes, and \n",
    "    returns tuples for training and test features and their corresponding class labels.\n",
    "       \n",
    "       param complete_df: A dataframe with our processed text data, datatypes, and labels\n",
    "       param features_df: A dataframe of similarity features\n",
    "       param selected_features: An array of selected features in `features_df`\n",
    "       return: training and test features and labels: (train_x, train_y), (test_x, test_y)'''\n",
    "    \n",
    "    df = pd.concat([complete_df, features_df], axis=1)\n",
    "    # get the training features\n",
    "    train_x = df[df['Datatype']=='train'].drop('Class', axis=1)\n",
    "    train_x = train_x[selected_features].values\n",
    "    # And training class labels (0 or 1)\n",
    "    train_y = df[df['Datatype']=='train']['Class'].values\n",
    "    \n",
    "    # get the test features and labels\n",
    "    test_x = df[df['Datatype']=='test'].drop('Class', axis=1)\n",
    "    test_x = test_x[selected_features].values\n",
    "    test_y = df[df['Datatype']=='test']['Class'].values\n",
    "    \n",
    "    return (train_x, train_y), (test_x, test_y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size:  70\n",
      "Test size:  25\n",
      "\n",
      "Training df sample: \n",
      " [[0.39814815 0.07906977 0.00934579 0.         0.19178082]\n",
      " [1.         0.98469388 0.96410256 0.94329897 0.82075472]\n",
      " [0.86936937 0.71945701 0.61363636 0.51598174 0.84649123]\n",
      " [0.59358289 0.2688172  0.15675676 0.10869565 0.31606218]\n",
      " [0.54450262 0.11578947 0.03174603 0.00531915 0.24257426]\n",
      " [0.32950192 0.05384615 0.00772201 0.00387597 0.16117216]\n",
      " [0.59030837 0.15044248 0.03555556 0.00446429 0.30165289]\n",
      " [0.76530612 0.70989761 0.66438356 0.62542955 0.62171053]\n",
      " [0.75977654 0.50561798 0.39548023 0.30681818 0.48430493]\n",
      " [0.88444444 0.52678571 0.34080717 0.24774775 0.59745763]]\n"
     ]
    }
   ],
   "source": [
    "# Selecting our best features\n",
    "selected_features = ['c_1', 'c_2','c_3','c_4', 'lcs_word']\n",
    "\n",
    "(train_x, train_y), (test_x, test_y) = train_test_data(complete_df, features_df, selected_features)\n",
    "\n",
    "# These should add up to 95 (100 - 5 original files)\n",
    "print('Training size: ', len(train_x))\n",
    "print('Test size: ', len(test_x))\n",
    "print()\n",
    "print('Training df sample: \\n', train_x[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Creating Final Data Files\n",
    "\n",
    "\n",
    "We need to access the train and test data in SageMaker and upload it to S3. In this project, SageMaker will expect the following format for your train/test data:\n",
    "* Training and test data should be saved in one `.csv` file each, ex `train.csv` and `test.csv`\n",
    "* These files should have class  labels in the first column and features in the rest of the columns\n",
    "\n",
    "This format follows the practice, outlined in the [SageMaker documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html), which reads: \"Amazon SageMaker requires that a CSV file doesn't have a header record and that the target variable [class label] is in the first column.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_csv(x, y, filename, data_dir):\n",
    "    '''\n",
    "    Merges features and labels and converts them into one csv file with labels in the first column.\n",
    "       param x: Data features\n",
    "       param y: Data labels\n",
    "       param file_name: Name of csv file, ex. 'train.csv'\n",
    "       param data_dir: The directory where files will be saved\n",
    "    '''\n",
    "    # make data dir, if it does not exist\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    \n",
    "    df = pd.concat([pd.Series(y), pd.DataFrame(x)], axis=1)\n",
    "    df.to_csv(path_or_buf=data_dir+'/'+filename, header=False, index=False)\n",
    "    \n",
    "    print('Path created: '+str(data_dir)+'/'+str(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path created: plagiarism_data/train.csv\n",
      "Path created: plagiarism_data/test.csv\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'plagiarism_data'\n",
    "\n",
    "make_csv(train_x, train_y, filename='train.csv', data_dir=data_dir)\n",
    "make_csv(test_x, test_y, filename='test.csv', data_dir=data_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
